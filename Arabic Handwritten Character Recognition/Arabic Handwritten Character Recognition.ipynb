{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Training and Testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the important libraries\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\alihi\\OneDrive\\Dokumente\\MLL project\\csvTrainImages 13440x1024.csv\", header= None)\n",
    "train_label = pd.read_csv(r\"C:\\Users\\alihi\\OneDrive\\Dokumente\\MLL project\\csvTrainLabel 13440x1.csv\", header= None)\n",
    "test_data= pd.read_csv(r\"C:\\Users\\alihi\\OneDrive\\Dokumente\\MLL project\\csvTestImages 3360x1024.csv\", header= None)\n",
    "test_label= pd.read_csv(r\"C:\\Users\\alihi\\OneDrive\\Dokumente\\MLL project\\csvTestLabel 3360x1.csv\", header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "(3360, 1024)\n",
      "(3360, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print (train_label.head(3))\n",
    "print (test_data.shape)\n",
    "print(test_label.shape)\n",
    "print(type(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "   0\n",
      "0  1\n",
      "1  1\n",
      "2  2\n",
      "3  2\n",
      "4  3\n",
      "[ 1  1  1 ... 28 28 28]\n"
     ]
    }
   ],
   "source": [
    "# Change the target data into 1d array\n",
    "\n",
    "train_label2= train_label.iloc[:,[0]]\n",
    "print(train_label2.head())\n",
    "\n",
    "test_label2= test_label.iloc[:,[0]]\n",
    "print(test_label2.head())\n",
    "\n",
    "train_label1= train_label2.values.ravel()\n",
    "print(train_label1)\n",
    "test_label1= test_label2.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27  8 11 ... 13 20 19]\n",
      "[17  8 26 ...  1  2  6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.033407738095238095"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying Randomness of the outputs (Number of the Alphabets)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "Random_Train_label= np.random.randint(0, 29, size=13440)\n",
    "print(Random_Train_label)\n",
    "\n",
    "Random_Test_label= np.random.randint(0, 29, size=3360)\n",
    "print(Random_Test_label)\n",
    "\n",
    "accuracy_score(train_label1, Random_Train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03184523809523809"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_label1,Random_Test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying KNN from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7110863095238096"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# APPLYING THE MODEL\n",
    "knn= KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_data, (train_label1))\n",
    "knn.score(train_data,(train_label1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [ 1  1  2 ...  8 28  8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5047619047619047"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction = knn.predict(test_data)\n",
    "print(\"Prediction: {}\".format(new_prediction))\n",
    "knn.score(test_data,np.ravel(test_label1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppot Vector Machine For Handwritten Charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Pipeline object\n",
    "pipe = [('scaler', StandardScaler()), ('SVM', SVC(kernel='poly'))]\n",
    "pipeline = Pipeline(pipe) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'SVM__C':[0.001, 0.1, 100, 10e5], 'SVM__gamma':[10,1,0.1,0.01]}\n",
    "searcher = GridSearchCV(pipeline, param_grid=parameters, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.fit(train_data, train_label1)\n",
    "print(\"Best train accuracy =\", searcher.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = searcher.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Best test accuracy =\",searcher.score(test_data, test_label1))\n",
    "print( \"best parameters from train data: \", searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data to numpy\n",
    "train_data = train_data.iloc[:,:].values.astype('float32')\n",
    "train_label = train_label.iloc[:,:].values.astype('int32')-1\n",
    "test_data = test_data.iloc[:,:].values.astype('float32')\n",
    "test_label = test_label.iloc[:,:].values.astype('int32')-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alihi\\Anaconda3\\envs\\newenvt\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "train_label = labelencoder_X.fit_transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to present in 2D\n",
    "train_data = train_data.reshape([-1, 32, 32, 1])\n",
    "test_data = test_data.reshape([-1, 32, 32, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the ouput as categorical\n",
    "train_label =np_utils.to_categorical(train_label,28)\n",
    "test_label =np_utils.to_categorical(test_label,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDG = ImageDataGenerator(rescale=1.0/255.0,\n",
    "        featurewise_center=False, \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.1,  \n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare an iterators to scale images\n",
    "train_iterator = IDG.flow(train_data, train_label, batch_size=64)\n",
    "test_iterator = IDG.flow(test_data, test_label, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (32,32,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',  activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',  activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units = 256, input_dim = 1024, activation = 'relu'))\n",
    "model.add(Dense(units = 256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(28, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 28)                7196      \n",
      "=================================================================\n",
      "Total params: 1,203,708\n",
      "Trainable params: 1,203,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 162s - loss: 2.6358 - acc: 0.2087\n",
      "Epoch 2/30\n",
      " - 102s - loss: 1.5824 - acc: 0.4839\n",
      "Epoch 3/30\n",
      " - 94s - loss: 1.1159 - acc: 0.6207\n",
      "Epoch 4/30\n",
      " - 95s - loss: 0.8233 - acc: 0.7171\n",
      "Epoch 5/30\n",
      " - 86s - loss: 0.6895 - acc: 0.7732\n",
      "Epoch 6/30\n",
      " - 86s - loss: 0.5591 - acc: 0.8182\n",
      "Epoch 7/30\n",
      " - 72s - loss: 0.4741 - acc: 0.8407\n",
      "Epoch 8/30\n",
      " - 70s - loss: 0.4424 - acc: 0.8574\n",
      "Epoch 9/30\n",
      " - 68s - loss: 0.3814 - acc: 0.8784\n",
      "Epoch 10/30\n",
      " - 66s - loss: 0.3647 - acc: 0.8875\n",
      "Epoch 11/30\n",
      " - 62s - loss: 0.3128 - acc: 0.8967\n",
      "Epoch 12/30\n",
      " - 60s - loss: 0.2938 - acc: 0.9054\n",
      "Epoch 13/30\n",
      " - 60s - loss: 0.2836 - acc: 0.9136\n",
      "Epoch 14/30\n",
      " - 59s - loss: 0.2646 - acc: 0.9199\n",
      "Epoch 15/30\n",
      " - 60s - loss: 0.2410 - acc: 0.9254\n",
      "Epoch 16/30\n",
      " - 61s - loss: 0.2211 - acc: 0.9311\n",
      "Epoch 17/30\n",
      " - 59s - loss: 0.2209 - acc: 0.9347\n",
      "Epoch 18/30\n",
      " - 59s - loss: 0.2204 - acc: 0.9327\n",
      "Epoch 19/30\n",
      " - 59s - loss: 0.2099 - acc: 0.9372\n",
      "Epoch 20/30\n",
      " - 59s - loss: 0.1835 - acc: 0.9426\n",
      "Epoch 21/30\n",
      " - 60s - loss: 0.2040 - acc: 0.9387\n",
      "Epoch 22/30\n",
      " - 64s - loss: 0.1786 - acc: 0.9462\n",
      "Epoch 23/30\n",
      " - 68s - loss: 0.1766 - acc: 0.9446\n",
      "Epoch 24/30\n",
      " - 75s - loss: 0.1639 - acc: 0.9516\n",
      "Epoch 25/30\n",
      " - 75s - loss: 0.1733 - acc: 0.9494\n",
      "Epoch 26/30\n",
      " - 77s - loss: 0.1661 - acc: 0.9517\n",
      "Epoch 27/30\n",
      " - 82s - loss: 0.1694 - acc: 0.9510\n",
      "Epoch 28/30\n",
      " - 78s - loss: 0.1732 - acc: 0.9483\n",
      "Epoch 29/30\n",
      " - 84s - loss: 0.1691 - acc: 0.9529\n",
      "Epoch 30/30\n",
      " - 87s - loss: 0.1725 - acc: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27235ee8b38>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_iterator,epochs = 30, verbose = 2, steps_per_epoch=train_data.shape[0] // 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_data)\n",
    "y_pred = np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12069274651862326, 0.9651785714285714]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(test_iterator, steps=len(test_iterator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
