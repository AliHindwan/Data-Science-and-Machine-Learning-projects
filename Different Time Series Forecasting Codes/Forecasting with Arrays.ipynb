{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting the Whole data with an Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data and the librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alihi\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "chdir=os.chdir(\"D:\\Folder D/New folder/WERK Student/EXCEL/\")\n",
    "print(chdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf\n",
    "import statsmodels.api as sm\n",
    "import pmdarima as pm\n",
    "plt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n",
    "%matplotlib inline\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tools.eval_measures import rmse, aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('201102_DataSet Forecast_0.01.csv',\n",
    "                 header=0, sep=';', parse_dates = ['transaction_date'], index_col = ['transaction_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorarty Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  warehouse_id  product_id  quantity\n",
       "transaction_date                                    \n",
       "1998-01-01                  10           4         3\n",
       "1998-01-01                  10          11         3\n",
       "1998-01-01                  10          12         3\n",
       "1998-01-01                  10          14         2\n",
       "1998-01-01                  10          16         3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 182883 entries, 1998-01-01 to 1998-12-30\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype\n",
      "---  ------        --------------   -----\n",
      " 0   warehouse_id  182883 non-null  int64\n",
      " 1   product_id    182883 non-null  int64\n",
      " 2   quantity      182883 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 5.6 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply forecasting on the Whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "Series to an array\n",
      "<class 'numpy.ndarray'>\n",
      "[10 10 10 ... 10 10 10]\n",
      "<class 'numpy.ndarray'>\n",
      "[   4   11   12 ... 1542 1544 1549]\n",
      "<class 'numpy.ndarray'>\n",
      "[3 3 3 ... 4 2 3]\n"
     ]
    }
   ],
   "source": [
    "#a = df[['transaction_date']].values\n",
    "b = pd.Series(df['warehouse_id'])\n",
    "c = pd.Series(df['product_id'])\n",
    "d = pd.Series(df['quantity'])\n",
    "print(type(b))\n",
    "print(type(c))\n",
    "print(type(d))\n",
    "print(\"Series to an array\")\n",
    "b_new = np.array(b.values.tolist())\n",
    "print(type(b_new))\n",
    "print(b_new)\n",
    "c_new = np.array(c.values.tolist())\n",
    "print(type(c_new))\n",
    "print(c_new)\n",
    "d_new = np.array(d.values.tolist())\n",
    "print(type(d_new))\n",
    "print(d_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10   10   10 ...   10   10   10]\n",
      " [   4   11   12 ... 1542 1544 1549]\n",
      " [   3    3    3 ...    4    2    3]]\n",
      "(3, 182883)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data1 = np.vstack([b, c,d])\n",
    "print(data1)\n",
    "print(data1.shape)\n",
    "print(type(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 0)\n",
      "reached exception\n",
      "(0, 0, 1)\n",
      "reached exception\n",
      "(0, 0, 2)\n",
      "reached exception\n",
      "(0, 0, 3)\n",
      "reached exception\n",
      "(0, 0, 4)\n",
      "reached exception\n",
      "(0, 1, 0)\n",
      "reached exception\n",
      "(0, 1, 1)\n",
      "reached exception\n",
      "(0, 1, 2)\n",
      "reached exception\n",
      "(0, 1, 3)\n",
      "reached exception\n",
      "(0, 1, 4)\n",
      "reached exception\n",
      "(0, 2, 0)\n",
      "reached exception\n",
      "(0, 2, 1)\n",
      "reached exception\n",
      "(0, 2, 2)\n",
      "reached exception\n",
      "(0, 2, 3)\n",
      "reached exception\n",
      "(0, 2, 4)\n",
      "reached exception\n",
      "(1, 0, 0)\n",
      "reached exception\n",
      "(1, 0, 1)\n",
      "reached exception\n",
      "(1, 0, 2)\n",
      "reached exception\n",
      "(1, 0, 3)\n",
      "reached exception\n",
      "(1, 0, 4)\n",
      "reached exception\n",
      "(1, 1, 0)\n",
      "reached exception\n",
      "(1, 1, 1)\n",
      "reached exception\n",
      "(1, 1, 2)\n",
      "reached exception\n",
      "(1, 1, 3)\n",
      "reached exception\n",
      "(1, 1, 4)\n",
      "reached exception\n",
      "(1, 2, 0)\n",
      "reached exception\n",
      "(1, 2, 1)\n",
      "reached exception\n",
      "(1, 2, 2)\n",
      "reached exception\n",
      "(1, 2, 3)\n",
      "reached exception\n",
      "(1, 2, 4)\n",
      "reached exception\n",
      "(2, 0, 0)\n",
      "reached exception\n",
      "(2, 0, 1)\n",
      "reached exception\n",
      "(2, 0, 2)\n",
      "reached exception\n",
      "(2, 0, 3)\n",
      "reached exception\n",
      "(2, 0, 4)\n",
      "reached exception\n",
      "(2, 1, 0)\n",
      "reached exception\n",
      "(2, 1, 1)\n",
      "reached exception\n",
      "(2, 1, 2)\n",
      "reached exception\n",
      "(2, 1, 3)\n",
      "reached exception\n",
      "(2, 1, 4)\n",
      "reached exception\n",
      "(2, 2, 0)\n",
      "reached exception\n",
      "(2, 2, 1)\n",
      "reached exception\n",
      "(2, 2, 2)\n",
      "reached exception\n",
      "(2, 2, 3)\n",
      "reached exception\n",
      "(2, 2, 4)\n",
      "reached exception\n",
      "(3, 0, 0)\n",
      "reached exception\n",
      "(3, 0, 1)\n",
      "reached exception\n",
      "(3, 0, 2)\n",
      "reached exception\n",
      "(3, 0, 3)\n",
      "reached exception\n",
      "(3, 0, 4)\n",
      "reached exception\n",
      "(3, 1, 0)\n",
      "reached exception\n",
      "(3, 1, 1)\n",
      "reached exception\n",
      "(3, 1, 2)\n",
      "reached exception\n",
      "(3, 1, 3)\n",
      "reached exception\n",
      "(3, 1, 4)\n",
      "reached exception\n",
      "(3, 2, 0)\n",
      "reached exception\n",
      "(3, 2, 1)\n",
      "reached exception\n",
      "(3, 2, 2)\n",
      "reached exception\n",
      "(3, 2, 3)\n",
      "reached exception\n",
      "(3, 2, 4)\n",
      "reached exception\n",
      "(4, 0, 0)\n",
      "reached exception\n",
      "(4, 0, 1)\n",
      "reached exception\n",
      "(4, 0, 2)\n",
      "reached exception\n",
      "(4, 0, 3)\n",
      "reached exception\n",
      "(4, 0, 4)\n",
      "reached exception\n",
      "(4, 1, 0)\n",
      "reached exception\n",
      "(4, 1, 1)\n",
      "reached exception\n",
      "(4, 1, 2)\n",
      "reached exception\n",
      "(4, 1, 3)\n",
      "reached exception\n",
      "(4, 1, 4)\n",
      "reached exception\n",
      "(4, 2, 0)\n",
      "reached exception\n",
      "(4, 2, 1)\n",
      "reached exception\n",
      "(4, 2, 2)\n",
      "reached exception\n",
      "(4, 2, 3)\n",
      "reached exception\n",
      "(4, 2, 4)\n",
      "reached exception\n"
     ]
    }
   ],
   "source": [
    "for p in range(5):\n",
    "    for d in range(3):\n",
    "        for q in range(5):\n",
    "            order = (p,d,q)    \n",
    "            try:\n",
    "                model = ARIMA(data, order=(p,d,q))\n",
    "                print(\"this works:{}, {}, {} \".format(p,d,q))\n",
    "            except:\n",
    "                print(order)\n",
    "                print('reached exception')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]\n",
      " [7 8]]\n",
      "(0, 0, 0)\n",
      "reached exception\n",
      "(0, 0, 1)\n",
      "reached exception\n",
      "(1, 0, 0)\n",
      "reached exception\n",
      "(1, 0, 1)\n",
      "reached exception\n",
      "(2, 0, 0)\n",
      "reached exception\n",
      "(2, 0, 1)\n",
      "reached exception\n",
      "(3, 0, 0)\n",
      "reached exception\n",
      "(3, 0, 1)\n",
      "reached exception\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Best model:  ARIMA(5,0,0)(0,0,0)[0] intercept\n",
    "\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "a = [1, 2]\n",
    "b = [3, 4]\n",
    "c = [5, 6]\n",
    "d = [7, 8]\n",
    "\n",
    "data = np.vstack([a, b, c, d])\n",
    "\n",
    "print(data.shape)\n",
    "print(data)\n",
    "\n",
    "for p in range(4):\n",
    "    for d in range(1):\n",
    "        for q in range(2):\n",
    "            order = (p,d,q)    \n",
    "            try:\n",
    "                model = ARIMA(data, order=(p,d,q))\n",
    "                print(\"this works:{}, {}, {} \".format(p,d,q))\n",
    "            except:\n",
    "                print(order)\n",
    "                print('reached exception')\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.dstack([a, b])\n",
    "model = statsmodels.tsa.arima_model.ARIMA(data, order=(5,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=8421369.698, Time=4.67 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=inf, Time=5.67 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=7718887.017, Time=50.91 sec\n",
      " ARIMA(1,0,1)(0,0,0)[0]             : AIC=5590446.121, Time=15.55 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=5590442.229, Time=21.28 sec\n",
      " ARIMA(2,0,0)(0,0,0)[0]             : AIC=inf, Time=9.36 sec\n",
      " ARIMA(3,0,1)(0,0,0)[0]             : AIC=5590447.621, Time=28.54 sec\n",
      " ARIMA(2,0,2)(0,0,0)[0]             : AIC=5590031.323, Time=82.00 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0]             : AIC=5590444.326, Time=20.01 sec\n",
      " ARIMA(3,0,2)(0,0,0)[0]             : AIC=5590477.813, Time=155.91 sec\n",
      " ARIMA(2,0,3)(0,0,0)[0]             : AIC=inf, Time=189.35 sec\n",
      " ARIMA(1,0,3)(0,0,0)[0]             : AIC=5590444.589, Time=22.54 sec\n",
      " ARIMA(3,0,3)(0,0,0)[0]             : AIC=5590452.988, Time=235.71 sec\n",
      " ARIMA(2,0,2)(0,0,0)[0] intercept   : AIC=5590169.844, Time=216.65 sec\n",
      "\n",
      "Best model:  ARIMA(2,0,2)(0,0,0)[0]          \n",
      "Total fit time: 1062.159 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:               548649\n",
      "Model:               SARIMAX(2, 0, 2)   Log Likelihood            -2795010.661\n",
      "Date:                Wed, 04 Nov 2020   AIC                        5590031.323\n",
      "Time:                        15:11:13   BIC                        5590087.399\n",
      "Sample:                             0   HQIC                       5590047.136\n",
      "                             - 548649                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          1.9819      0.002   1155.245      0.000       1.979       1.985\n",
      "ar.L2         -0.9819      0.002   -574.372      0.000      -0.985      -0.979\n",
      "ma.L1         -0.9944      0.003   -297.190      0.000      -1.001      -0.988\n",
      "ma.L2          0.0044      0.003      1.635      0.102      -0.001       0.010\n",
      "sigma2      1557.5527      1.568    993.403      0.000    1554.480    1560.626\n",
      "===================================================================================\n",
      "Ljung-Box (Q):                       43.68   Jarque-Bera (JB):       50890614269.60\n",
      "Prob(Q):                              0.32   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.23   Skew:                           -38.16\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                      1493.08\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "#auto_arima() uses a stepwise approach to search multiple combinations of p,d,q parameters\n",
    "#and chooses the best model that has the least AIC.\n",
    "\n",
    "model = pm.auto_arima(data1, start_p=0, start_q=0,\n",
    "                      test='adf',       # use adftest to find optimal 'd'\n",
    "                      max_p=5, max_q=5, # maximum p and q\n",
    "                      m=1,              # frequency of series\n",
    "                      d=None,           # let model determine 'd'\n",
    "                      seasonal=False,   # No Seasonality\n",
    "                      start_P=0, \n",
    "                      D=0, \n",
    "                      trace=True,\n",
    "                      error_action='ignore',  \n",
    "                      suppress_warnings=True, \n",
    "                      stepwise=True)\n",
    "\n",
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
